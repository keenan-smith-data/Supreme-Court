---
title: "Sitemap Cleaning"
author: "Keenan Smith"
date: '2022-07-10'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Library Initiation}
library(tidyverse)
```

```{r Right Websites Usable Links, eval=FALSE, include=FALSE}
nr_pol_raw <- read_delim("C:/Users/slaps/OneDrive/Documents/Programming/Data/nationalreviewpol.csv", delim = ";", show_col_types = FALSE)

nr_pol <-
  nr_pol_raw |>
  filter(
    str_detect(urlname, "wp-content", negate = TRUE),
    str_detect(url, "com/20")
  ) |>
  transmute(url) |>
  distinct(url) |>
  arrange(url)

write_rds(nr_pol, "data/nationalreview_pol_policy.rds", "gz", compression = 9L)

nr_law_courts_raw <- read_delim("C:/Users/slaps/OneDrive/Documents/Programming/Data/nationalreviewlawcourts.csv", delim = ";", show_col_types = FALSE)

nr_law_courts <-
  nr_law_courts_raw |>
  filter(
    str_detect(urlname, "wp-content", negate = TRUE),
    str_detect(url, "com/20")
  ) |>
  transmute(url) |>
  distinct(url) |>
  arrange(url)

write_rds(nr_law_courts, "data/nationalreview_law_courts.rds", "gz", compression = 9L)
```

```{r Left Websites Usable Links, eval=FALSE}
jacobin_raw <- read_rds("C:/Users/slaps/OneDrive/Documents/Programming/Data/jacobin_unfiltered.rds")

jacobin_exclude <- c(
  "wp-content", "format", "category", "jpg", "png", "gif",
  "com$", "\\?"
)
jacobin <-
  jacobin_raw |>
  filter(
    valid == TRUE,
    size > 1,
    is.na(infostring),
    str_detect(url, "jacobin\\.com/20"),
    str_detect(url, paste(jacobin_exclude, collapse = "|"), negate = TRUE)
  )

jacobin_mod <-
  jacobin |>
  distinct(url)

jacobin_mod <-
  jacobin_mod |>
  mutate(year = as.numeric(str_extract(url, "\\d\\d\\d\\d"))) |>
  filter(year > 2018) |>
  arrange(desc(year))

write_rds(jacobin_mod, "data/jacobin.rds", "gz", compression = 9L)

thenation_raw <- read_rds("C:/Users/slaps/OneDrive/Documents/Programming/Data/thenation_unfilted.rds")

thenation_exclude <- c(
  "wp-", "com$", "/feed/$", "html$", "tnamp/$", "#",
  "\\?", "%"
)

thenation <-
  thenation_raw |>
  filter(
    valid == TRUE,
    size > 1,
    is.na(infostring),
    str_detect(url, "thenation\\.com/article"),
    str_detect(url, paste(thenation_exclude, collapse = "|"), negate = TRUE)
  )

thenation_mod <-
  thenation |>
  distinct(url) |>
  arrange(url)

write_rds(thenation_mod, "data/thenation.rds", "gz", compression = 9L)
```

```{r Claremont Websites Usable Links, eval=FALSE}
features_raw <- read_delim("C:/Users/slaps/OneDrive/Documents/Programming/Data/americanmindfeatures.csv", delim = ";", show_col_types = FALSE)

memos_raw <- read_delim("C:/Users/slaps/OneDrive/Documents/Programming/Data/americanmindmemos.csv", delim = ";", show_col_types = FALSE)

salvos_raw <- read_delim("C:/Users/slaps/OneDrive/Documents/Programming/Data/americanmindsalvos.csv", delim = ";", show_col_types = FALSE)

claremont_raw <- read_delim("C:/Users/slaps/OneDrive/Documents/Programming/Data/claremontreviewessays.csv", delim = ";", show_col_types = FALSE)

features_exclude <- c("oembed", "twitter", "features/$", "\\.com$", "google\\.com/")

features <-
  features_raw |>
  filter(
    valid == TRUE,
    size > 1,
    str_detect(url, "americanmind\\.org/features/"),
    str_detect(url, paste(features_exclude, collapse = "|"), negate = TRUE)
  ) |>
  distinct(url) |>
  arrange(url)

write_rds(features, "data/americanmindfeatures.rds", "gz", compression = 9L)

memos <-
  memos_raw |>
  filter(
    valid == TRUE,
    str_detect(url, "org/memo/")
  ) |>
  distinct(url) |>
  arrange(url)

write_rds(memos, "data/americanmindmemos.rds", "gz", compression = 9L)

salvos <-
  salvos_raw |>
  filter(
    valid == TRUE,
    str_detect(url, "org/salvo/")
  ) |>
  distinct(url) |>
  arrange(url)

write_rds(salvos, "data/americanmindsalvos.rds", "gz", compression = 9L)

claremont_exclude <- c(
  "/auth", "/issue", "/article", "/subscribe", "/podcast/",
  "/donate", "/advertising/", "/archive", "/faqs/",
  "/about-us/", "/my-account/", "/contact-us/", "/digital-exclusive/",
  "/publication-committee/", "com/$", "com$", "wp-"
)


claremont <-
  claremont_raw |>
  filter(
    valid == TRUE,
    str_detect(url, "claremontreviewofbooks\\.com"),
    str_detect(url, paste(claremont_exclude, collapse = "|"), negate = TRUE)
  ) |>
  distinct(url) |>
  arrange(url)

write_rds(claremont, "data/claremontreviewessays.rds", "gz", compression = 9L)
```


```{r Heritage Website Usable Links}
# heritage_raw <- read_delim("C:/Users/slaps/OneDrive/Documents/Programming/Data/heritage.csv", delim = ";", show_col_types = FALSE)

# write_rds(heritage_raw, "C:/Users/slaps/OneDrive/Documents/Programming/Data/heritage.rds", "gz", compression = 9L)

heritage_raw <- read_rds("C:/Users/slaps/OneDrive/Documents/Programming/Data/heritage.rds")

heritage_exclude <- c("mailto", "staff", "wp-", "\\.com", "html$", "#", "\\?", "%", "=")
heritage_include <- c("commentary", "report")

heritage <-
  heritage_raw |>
  filter(
    valid == TRUE,
    str_detect(infostring, "denied", negate = TRUE),
    str_detect(url, "www\\.heritage\\.org"),
    str_detect(url, paste(heritage_exclude, collapse = "|"), negate = TRUE),
    str_detect(url, paste(heritage_include, collapse = "|"))
  )

heritage_final <-
  heritage |>
  distinct(url) |>
  arrange(url)

heritage_commentary <-
  heritage_final |>
  filter(str_detect(url, "commentary"))

heritage_report <-
  heritage_final |>
  filter(str_detect(url, "report"))

write_rds(heritage_commentary, "data/heritage_commentary.rds", "gz", compression = 9L)
write_rds(heritage_report, "data/heritage_report.rds", "gz", compression = 9L)
```
