---
title: "Text Scraping"
author: "Keenan Smith"
date: '2022-07-200'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Library Initiation}
library(tidyverse)
library(rvest)
```


```{r Functions}
data_split <- function(data, n_groups = 10) {
  temp <- data
  temp$group <- 1:nrow(temp) %% n_groups + 1
  temp_list <- split(temp, temp$group)
  return(temp_list)
}

# American Mind Article Pull
american_mind_pull <- function(hyperlink) {
  temp <- rvest::read_html(hyperlink)
  art_link <- hyperlink
  art_title <-
    temp |>
    rvest::html_elements(css = ".tam__single-header-title") |>
    rvest::html_text2()
  art_author <-
    temp |>
    rvest::html_elements(css = ".tam__single-header-author") |>
    rvest::html_nodes("a") |>
    rvest::html_text2()
  if (length(art_author) > 1) {
    art_author = paste(art_author, collapse = ", ")
  } else if (length(art_author) == 1) {
    art_author = art_author
  } else {
    art_author = NA
  }
  art_date <-
    temp |>
    rvest::html_elements(css = ".tam__single-header-meta-date") |>
    rvest::html_text2() |>
    stringr::str_replace("\\.", "/") |>
    lubridate::mdy()
  text_data <-
    temp |>
    rvest::html_nodes(".tam__single-content-output") |>
    rvest::html_nodes("p") |>
    rvest::html_text2() |>
    dplyr::as_tibble() |>
    dplyr::rename(text = value) |>
    dplyr::mutate(
      art_title = art_title,
      art_author = art_author,
      art_date = art_date,
      art_link = art_link
    )
  return(text_data)
}

am_mind_pull_try <- function(hyperlink) {
  tryCatch(
    expr = {
      message(paste("Trying", hyperlink))
      american_mind_pull(hyperlink)
    },
    error = function(cond) {
      message(paste("This URL has caused an error:", hyperlink))
      message(cond)
    },
    warning = function(cond) {
      message(paste("URL has a warning:", hyperlink))
      message(cond)
    },
    finally = {
      message(paste("Processed URL:", hyperlink))
      Sys.sleep(5)
    }
  )
}

# Jacobin Article Pull
jacobin_pull <- function(hyperlink) {
  temp <- rvest::read_html(hyperlink)
  art_link <- hyperlink
  art_title <-
    temp |>
    rvest::html_elements(css = ".po-hr-cn__title") |>
    rvest::html_text2()
  art_author <-
    temp |>
    rvest::html_elements(css = ".po-hr-cn__author-link") |>
    rvest::html_text2()
  if (length(art_author) > 1) {
    art_author = paste(art_author, collapse = ", ")
  } else if (length(art_author) == 1) {
    art_author = art_author
  } else {
    art_author = NA
  }
  art_date <-
    temp |>
    rvest::html_elements(css = ".po-hr-fl__date") |>
    rvest::html_text2() |>
    stringr::str_replace("\\.", "/") |>
    lubridate::mdy()
  text_data <-
    temp |>
    rvest::html_element(css = "#post-content") |>
    rvest::html_nodes("p") |>
    rvest::html_text2() |>
    dplyr::as_tibble() |>
    dplyr::rename(text = value) |>
    dplyr::mutate(
      art_title = art_title,
      art_author = art_author,
      art_date = art_date,
      art_link = art_link
    )
  return(text_data)
}

jacobin_pull_tests <- function(hyperlink) {
  session <- read_html(hyperlink)
  return(session)
}

j_pull_try <- function(hyperlink) {
  tryCatch(
    expr = {
      message(paste("Trying", hyperlink))
      jacobin_pull(hyperlink)
    },
    error = function(cond) {
      message(paste("This URL has caused an error:", hyperlink))
      message(cond)
    },
    warning = function(cond) {
      message(paste("URL has a warning:", hyperlink))
      message(cond)
    },
    finally = {
      message(paste("Processed URL:", hyperlink))
      Sys.sleep(5)
    }
  )
}

# Heritage Article Pull
heritage_com_pull <- function(hyperlink) {
  date_formats <- c("\\w\\w\\w \\d\\w\\w, \\d\\d\\d\\d", "\\w\\w\\w \\d\\d\\w\\w, \\d\\d\\d\\d")
  authors <- c(".author-card__name", "author-card__multi-name")
  temp <- rvest::read_html(hyperlink)
  art_link <- hyperlink
  art_title <-
    temp |>
    rvest::html_elements(css = ".commentary__headline") |>
    rvest::html_text2()
  art_author_1 <-
    temp |>
    rvest::html_nodes(".author-card__name") |>
    rvest::html_text2()
  art_author_2 <-
    temp |>
    rvest::html_nodes(".author-card__multi-name") |>
    rvest::html_text2()
  art_author <- c(art_author_1, art_author_2)
  if (length(art_author) > 1) {
    art_author = paste(art_author, collapse = ", ")
  } else if (length(art_author) == 1) {
    art_author = art_author
  } else {
    art_author = NA
  }
  art_date <-
    temp |>
    rvest::html_elements(css = ".article-general-info") |>
    rvest::html_text2() |>
    stringr::str_extract(paste(date_formats, collapse = "|")) |>
    lubridate::mdy()
  text_data <-
    temp |>
    rvest::html_nodes(".article__body-copy") |>
    rvest::html_nodes("p") |>
    rvest::html_text2() |>
    dplyr::as_tibble() |>
    dplyr::rename(text = value) |>
    dplyr::mutate(
      art_title = art_title,
      art_author = art_author,
      art_date = art_date,
      art_link = art_link
    )
  return(text_data)
}

heritage_pull_test <- function(hyperlink) {
  authors <- c(".author-card__name", ".author-card__multi-name")
  temp <- rvest::read_html(hyperlink)
  art_author_1 <-
    temp |>
    rvest::html_nodes(".author-card__name") |>
    rvest::html_text2()
  art_author_2 <-
    temp |>
    rvest::html_nodes(".author-card__multi-name") |>
    rvest::html_text2()
  art_author <- c(art_author_1, art_author_2)
  if (length(art_author) > 1) {
    art_author = paste(art_author, collapse = ", ")
  } else if (length(art_author) == 1) {
    art_author = art_author
  } else {
    art_author = NA
  }
  return(art_author)
}

h_com_pull_try <- function(hyperlink) {
  tryCatch(
    expr = {
      message(paste("Trying", hyperlink))
      heritage_com_pull(hyperlink)
    },
    error = function(cond) {
      message(paste("This URL has caused an error:", hyperlink))
      message(cond)
    },
    warning = function(cond) {
      message(paste("URL has a warning:", hyperlink))
      message(cond)
    },
    finally = {
      message(paste("Processed URL:", hyperlink))
      Sys.sleep(5)
    }
  )
}

# Heritage Article Pull
heritage_rep_pull <- function(hyperlink) {
  date_formats <- c("\\w\\w\\w \\d\\w\\w, \\d\\d\\d\\d", "\\w\\w\\w \\d\\d\\w\\w, \\d\\d\\d\\d")
  temp <- rvest::read_html(hyperlink)
  art_link <- hyperlink
  art_title <-
    temp |>
    rvest::html_elements(css = ".headline") |>
    rvest::html_text2()
  art_author <- "The Heritage Foundation"
  art_date <-
    temp |>
    rvest::html_elements(css = ".article-general-info") |>
    rvest::html_text2() |>
    stringr::str_extract(paste(date_formats, collapse = "|")) |>
    lubridate::mdy()
  text_data <-
    temp |>
    rvest::html_nodes(".article__body-copy") |>
    rvest::html_nodes("p") |>
    rvest::html_text2() |>
    dplyr::as_tibble() |>
    dplyr::rename(text = value) |>
    dplyr::mutate(
      art_title = art_title,
      art_author = art_author,
      art_date = art_date,
      art_link = art_link
    )
  return(text_data)
}

h_rep_pull_try <- function(hyperlink) {
  tryCatch(
    expr = {
      message(paste("Trying", hyperlink))
      heritage_rep_pull(hyperlink)
    },
    error = function(cond) {
      message(paste("This URL has caused an error:", hyperlink))
      message(cond)
    },
    warning = function(cond) {
      message(paste("URL has a warning:", hyperlink))
      message(cond)
    },
    finally = {
      message(paste("Processed URL:", hyperlink))
      Sys.sleep(5)
    }
  )
}
```


```{r Importing Cleaned Sitemaps}
jacobin <- read_rds("data/jacobin.rds")
# thenation <- read_rds("data/thenation.rds")
# claremont <- read_rds("data/claremontreviewessays.rds")
features <- read_rds("data/americanmindfeatures.rds")
memos <- read_rds("data/americanmindmemos.rds")
salvos <- read_rds("data/americanmindsalvos.rds")
h_commentary <- read_rds("data/heritage_commentary.rds")
h_report <- read_rds("data/heritage_report.rds")
```


```{r Test Links}
j_tl <- "https://jacobin.com/2022/07/we-still-have-to-take-donald-trump-seriously"
j_tl_2 <- "https://jacobin.com/2022/07/ukraine-russia-war-debt-forgiveness-us-eu"
j_tl_3 <- "https://jacobin.com/2022/06/american-exceptionalism-off-the-rails"
j_tl_wrong <- "https://jacobin.com/2022/06/american-exceptionae-off-the-rails"

h_com_tl <- "https://www.heritage.org/agriculture/commentary/conservative-farm-bill-must-include-major-subsidy-and-regulatory-reforms"
h_com_tl_2 <- "https://www.heritage.org/africa/commentary/kenyan-forces-are-allowing-money-flow-terrorist-group-somalia"
h_com_tl_3 <- "https://www.heritage.org/american-founders/commentary/pulitzer-overlooks-egregious-errors-award-prize-new-york-times-fatally"
h_com_tl_wrong <- "https://www.heritage.org/american-founders/commentary/pulitzer-overlooks-eggious-errors-award-prize-new-york-times-fatally"

h_rep_tl <- "https://www.heritage.org/agriculture/report/10-policy-recommendations-the-2018-farm-bill"
h_rep_tl_2 <- "https://www.heritage.org/american-founders/report/independence-forever-the-225th-anniversary-the-fourth-july"
h_rep_tl_3 <- "https://www.heritage.org/arms-control/report/arms-control-the-heritage-foundation-recommendations"
h_rep_tl_wrong <- "https://www.heritage.org/arms-control/report/arms-cont-the-heritage-foundation-recommendations"

j_test_vec <- c(j_tl, j_tl_2, j_tl_3)
h_com_test_vec <- c(h_com_tl, h_com_tl_2, h_com_tl_3)
h_rep_test_vec <- c(h_rep_tl, h_rep_tl_2, h_rep_tl_3)

j_test_wrong <- c(j_tl_wrong, j_tl, j_tl_2, j_tl_3)
h_com_test_wrong <- c(h_com_tl_wrong, h_com_tl, h_com_tl_2, h_com_tl_3)
h_rep_test_wrong <- c(h_rep_tl_wrong, h_rep_tl, h_rep_tl_2, h_rep_tl_3)
```


<https://stackoverflow.com/questions/29402528/append-data-frames-together-in-a-for-loop>
Absolute Legend of Help for R ways of doing loops

```{r Testing Iterations}
j_data_list <- list()
h_com_data_list <- list()
h_rep_data_list <- list()

for (i in 1:3) {
  j_test_df <- j_pull_try(j_test_vec[i])
  j_test_df$i <- i
  j_data_list[[i]] <- j_test_df
  
  h_com_test_df <- h_com_pull_try(h_com_test_vec[i])
  h_com_test_df$i <- i
  h_com_data_list[[i]] <- h_com_test_df
  
  h_rep_test_df <- h_rep_pull_try(h_rep_test_vec[i])
  h_rep_test_df$i <- i
  h_rep_data_list[[i]] <- h_rep_test_df
}

j_text_test <- bind_rows(j_data_list)
h_com_text_test <- bind_rows(h_com_data_list)
h_rep_text_test <- bind_rows(h_rep_data_list)
```


```{r}
j_wrong <- list()
h_com_wrong <- list()
h_rep_wrong <- list()

for (i in seq_along(j_test_wrong)) {
  j_test_df_wrong <- j_pull_try(j_test_wrong[i])
  j_test_df$i <- i
  j_wrong[[i]] <- j_test_df_wrong
  
  h_com_test_df_wrong <- h_com_pull_try(h_com_test_wrong[i])
  h_com_test_df_wrong$i <- i
  h_com_wrong[[i]] <- h_com_test_df_wrong
  
  h_rep_test_df_wrong <- h_rep_pull_try(h_rep_test_wrong[i])
  h_rep_test_df_wrong$i <- i
  h_rep_wrong[[i]] <- h_rep_test_df_wrong
}

j_text_wrong <- bind_rows(j_wrong)
h_com_text_wrong <- bind_rows(h_com_wrong)
h_rep_text_wrong <- bind_rows(h_rep_wrong)
```


```{r Splitting and Sampling the Massive URL dataframes}
numbers <- c(1:10)

j_list <- data_split(jacobin)
h_com_list <- data_split(h_commentary)
h_rep_list <- data_split(h_report)

h_order <- sample(numbers, 10)
j_order <- sample(numbers, 10)
```


```{r Testing Web Scrapes}
am_mind_test <- am_mind_pull_try(am_mind_memo)
am_mind_test_2 <- am_mind_pull_try(am_mind_salvo)
am_mind_test_3 <- am_mind_pull_try(am_mind_feature)

jac_test <- j_pull_tests(j_tl)
jac_test_2 <- j_pull_try(j_tl_2)
jac_test_3 <- j_pull_try(j_tl_3)

her_test <- h_com_pull_try(h_com_tl)
her_test_2 <- h_com_pull_try(h_com_tl_2)
her_rep_test <- h_rep_pull_try(h_rep_l)
```

```{r Initiating Empty Lists for Loops}
j_data_list <- list()
h_com_data_list <- list()
h_rep_data_list <- list()
```


```{r Massive Webscraping }
memo_text <- map_dfr(.x = memos$url, .f = am_mind_pull_try)

salvo_text <- map_dfr(.x = salvos$url, .f = am_mind_pull_try)

feature_text <- map_dfr(.x = features$url, .f = am_mind_pull_try)

for (i in numbers) {
  j_temp_df <- map_dfr(.x = j_list[[j_order[1]]]$url, .f = j_pull_try)
  j_temp_df$i <- i
  j_data_list[[i]] <- j_temp_df
  
  h_com_temp_df <- map_dfr(.x = h_com_list[[h_order[i]]]$url, .f = h_com_pull_try)
  h_com_temp_df$i <- i
  h_com_data_list[[i]] <- h_com_temp_df
  
  h_rep_temp_df <- map_dfr(.x = h_rep_list[[h_order[i]]]$url, .f = h_rep_pull_try)
  h_rep_temp_df$i <- i
  h_rep_data_list[[i]] <- h_rep_temp_df
}
```


```{r Binding Data Lists Together into a giant data frame}
jacobin_text <- bind_rows(j_data_list)
h_com_text <- bind_rows(h_com_data_list)
h_rep_text <- bind_rows(h_rep_data_list)
```


```{r Adding Source and Writing Data to RDS, eval=FALSE, include=FALSE}
memo_text <-
  memo_text |>
  mutate(text_source = "American Mind Memos")

salvo_text <-
  salvo_text |>
  mutate(text_source = "American Mind Salvos")

feature_text <-
  feature_text |>
  mutate(text_source = "American Mind Features")

jacobin_text <-
  jacobin_text |>
  mutate(text_source = "Jacobin")

h_com_text <-
  heritage_com_text |>
  mutate(text_source = "Heritage Commentary")

h_rep_text <-
  heritage_rep_text |>
  mutate(text_source = "Heritage Report")

write_rds(memo_text, "data/memo_text.rds", "gz", compression = 9L)
write_rds(salvo_text, "data/salvo_text.rds", "gz", compression = 9L)
write_rds(feature_text, "data/feature_text.rds", "gz", compression = 9L)
write_rds(jacobin_text, "data/jacobin_text.rds", "gz", compression = 9L)
write_rds(h_com_text, "data/heritage_com_text.rds", "gz", compression = 9L)
write_rds(h_rep_text, "data/heritage_rep_text.rds", "gz", compression = 9L)
```
